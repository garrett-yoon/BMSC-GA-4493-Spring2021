{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning in Medicine\n",
    "### BMSC-GA 4493, BMIN-GA 3007 \n",
    "### Spring 2021\n",
    "### Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Learning Objectives**:\n",
    "\n",
    "1. Basic Math Revision.\n",
    "2. Introduction to Machine Learning.\n",
    "3. Logistic Regression Model.\n",
    "4. Multi-layer Perceptron Model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instruction** \n",
    "\n",
    "1. If you need to write mathematical terms, you can type your answeres in a Markdown Cell via LaTex. See: <a href=\"https://stackoverflow.com/questions/13208286/how-to-write-latex-in-ipython-notebook\">here</a> if you have issues with writing equations. To see basic LaTex notation see: <a href=\"https://en.wikibooks.org/wiki/LaTeX/Mathematics\"> here </a>.\n",
    "\n",
    "2. Upload and Submit your final jupyter notebook file in <a href='http://newclasses.nyu.edu '>newclasses.nyu.edu</a>\n",
    "\n",
    "3. Deadline: Thursday Feb 25th 2021 (3pm) **\n",
    "\n",
    "4. ***HW submission instructions:*** Students should submit a zipped folder named netid_hwx where x is the hw number . The submission should consist of jupyter notebook with all the plots and expected outputs clearly visible in it. The zipped folder should also contain the data files. We should be able to run your ipynb without making directory changes. Not following the protocol might lead to deduction of scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Question 1: Math and Machine Learning Revision (20 points)\n",
    "\n",
    "### Take derivatives of functions from 1.1 to 1.8; calculate loss in 1.9 and 1.10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. (2 point)\n",
    "\n",
    "$f(x) = {e^{e^x} + 2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. (2 point)\n",
    "\n",
    "$f(x) = \\sqrt{\\sum_{i=1}^{100}(a_i x)}$\n",
    "\n",
    "($a_1$, $a_2$, $a_3$ and $a_{100}$ are constants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. (2 point)\n",
    "\n",
    "$f(x) = ln(x+2^x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. (2 point)\n",
    "\n",
    "$f(x) = ln(4^x * 7^x)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. (2 point)\n",
    "\n",
    "$f(x) = \\frac{1}{1+e^{-x}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. (2 point)\n",
    "$f(x) = \\frac{1}{1+e^{-ax-b}}$\n",
    "\n",
    "($a$ and $b$ are constants)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. (2 point)\n",
    "$f(x) = \\sum_{i=1}^{4}ln(a_i x^2 + b_i)$\n",
    "\n",
    "($a_i$s and $b_i$s are constants)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.8. (2 point)\n",
    "Now consider $X$ is a d-dimensional variable. i.e. $X=(x_1, x_2, ... , x_d)$. Consider $A = (a_i, a_1, ..., a_d)$ to also be a variables. \n",
    "\n",
    "Compute partial derivative of $f(X,A)$ with respect to each $x_i$, and each $a_i$:\n",
    "\n",
    "$f(X, A) = \\sum_{i=1}^{d}{ln(a_ix_i)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.9. (2 point)\n",
    "We have predicted values $Z$ from a model and true labels $Y$. Calculate root mean square error (RMSE) using $numpy$ only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Z=[0.8585, 0.7474, 0.9393, 0.0121, 0.7564, 0.0005, 0.8293, 0.3114]\n",
    "Y=[1,0,1,0,1,0,1,1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.10. (2 point)\n",
    "We have predicted values $Z$ from a model and true labels $Y$. Calculate average cross entropy using $numpy$ only (using the given epsilon value to avoid undefined log problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Z = np.array([[0.65,0.19,0.12,0.04], [0.21,0.01,0.34,0.44]])\n",
    "Y = np.array([[0,0,0,1], [0,0,1,0]])\n",
    "\n",
    "def cross_entropy(predictions, targets, epsilon=1e-12):\n",
    "    ###############\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Question 2: Solving Linear Regression via Mean Squared Error (MSE) Optimization Problem (25 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagine that you have measured two variables X and Y, for a simple task, and you belive that they might be linearly related to each other. Here, our input X has 2 dimensions, and the output has 1 dimension. We will use super-script to indicate which sample it is, and sub-scipt to indicate which dimension it is. \n",
    "The measurements are as follows:\n",
    "\n",
    "###### (Training data D = {($X^1$, $Y^1$), ($X^2$, $Y^2$), ($X^3$, $Y^3$)})\n",
    "\n",
    "Sample 1: $X^1 = (x_1^1, x_2^1) = (1, 2)$,   $Y^1$ = 3\n",
    "\n",
    "Sample 2: $X^2 = (x_1^2, x_2^2) = (3, 4)$,   $Y^2$ = 5\n",
    "\n",
    "Sample 3: $X^3 = (x_1^3, x_2^3) = (0, -1)$,   $Y^3$ = 6\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we assume that the relationship between X and Y is linear, we can write this relationship as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Y = f_{W,B}(X) = WX + B = w_1*x_1 + w_2*x_2 + B$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $W = (w_1, w_2)$ and $B$ are the parameters of the model.\t\n",
    "We are interested in finding best values for W and B.\t\n",
    "We define 'best' in terms of a loss function between $f_{W,b}(X_i)$ and $Y_i$ for each ($X_i$ and $Y_i$) in the training data. \t\n",
    "Since $Y_i$s are real numbers, let's consider Mean Squared Error loss. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that Mean Squared Error for this function, over training data, and W and B is:\n",
    "\n",
    "$MSELoss(D={(X_1, Y_1), (X_2, Y_2), (X_3, Y_3)}), W, B) = \\frac{1}{3}\\sum_{i=1}^{3} (f_{W,B}(X_i) - Y_i)^2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. (3 points)\n",
    "Compute the partial derivative of $MESLoss(D, W, B)$, With respect to W and B.\t\n",
    "Remember that $X_1$, $X_2$, $X_3$, $Y_1$, $Y_2$, and $Y_3$ are constants, and already given to us as training data above.\n",
    "\n",
    "$\\frac{d}{d w_1} MSELoss(D, W, B) = ?$\n",
    "\n",
    "$\\frac{d}{d w_2} MSELoss(D, W, B) = ?$\n",
    "\n",
    "$\\frac{d}{d B} MSELoss(D, W, B) = ?$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. (3 points)\n",
    "Use matplotlib library and plot $\\frac{d}{d w1} MSELoss(D, W, B)$ for $w_1 = np.arange(0, 5, 0.5)$, when $w_2$ equals -2, and B equals to 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "w1 = np.arange(0, 5, 0.5)\n",
    "# plot dMSELoss/dw1 here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3. (3 points)\n",
    "What values of $w_1$, $w_2$ and $B$, make all partial derivatives zero?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4. (6 points)\n",
    "If you start from an initial point $w_1^0 = 0.1$ , $w_2^0 = 0.1$ and $B^0 = 0.1$, and iteratively update your $w_1$, $w_2$, and B via gradient descent as follows:\n",
    "    \n",
    "$ w_1^{t+1} = w_1^t - 0.01 * \\frac{d}{d w_1} MSELoss(D, W, B) |_{w_1^t,w_2^t,B^t} $\t\n",
    "$ w_2^{t+1} = w_2^t - 0.01 * \\frac{d}{d w_2} MSELoss(D, W, B) |_{w_1^t,w_2^t,B^t} $\t\n",
    "$ B^{t+1} = B^t - 0.01 * \\frac{d}{d B} MSELoss(D, W, B) |_{w_1^t,w_2^t,B^t} $\t\n",
    "(Note: This is gradient descent with a 0.01 learning rate.)\n",
    "\n",
    "What are the values of Ws and B over iterations 0 to 1000? (Don't compute by hand! Write a code!)\t\n",
    "Write a python script that computes these values for 1000 iterations, i.e. lists of $\\{w_1^0, w^1_1,.., w_1^{1000}\\}$, $\\{w_2^0, w_2^1,.., w_2^{1000}\\}$, and $\\{B^0, B^1,.., B^{1000}\\}$.\t\n",
    "Plot the lists of $w_1$s, $w_2$s and Bs over 1000 iterations.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5. (10 points)\n",
    "Now that you learned the math and made the code yourself, we will use pytorch and automatic differentiation, to find optimal W and B!\t\n",
    "Again, consider data to be D = {($X_1$, $Y_1$), ($X_2$, $Y_2$), ($X_3$, $Y_3$)}) = {((1,2), 3), ((3,4), 5), ((0,-1), 6)}.\n",
    "\n",
    "Some of your steps are here. Fill in the rest and show a plot of the loss function, $w_1$, $w_2$ and B over these 1000 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data X is: [(2, 2), (2, 7), (-1, 0)]\n",
      "data Y is: [5, 3, 1]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch import optim\n",
    "\n",
    "D = [((1,2), 3), ((3,4), 5), ((0,-1), 6)]\n",
    "X = [d[0] for d in D]\n",
    "Y = [d[1] for d in D]\n",
    "print('data X is:', X)\n",
    "print('data Y is:', Y)\n",
    "\n",
    "model = torch.nn.Linear(2, 1, bias=True)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "loss = torch.nn.MSELoss()\n",
    "\n",
    "losslist = []\n",
    "w1list = []\n",
    "w2list = []\n",
    "blist = []\n",
    "\n",
    "# for epoch in range(1000):\n",
    "    # Shuffle your training data samples\n",
    "    # Loop over your training data in the new order:\n",
    "        #dont forget to: optimizer.zero_grad()\n",
    "        #prepare your x_input and y_target if needed\n",
    "        #send the data through your model: i.e. pred_i = model(x_input)\n",
    "        #send the prediction through the loss function too: i.e. lossout= loss(pred_i, y_target)\n",
    "        #call backward to back-propagate: i.e. lossout.backward()\n",
    "        #call optimizer.step() to update the model parameters based on the computed gradients\n",
    "        #keep the w1s, w2s, and bs, and loss value some list so you can plot them later\n",
    "\n",
    "#plot the losslist, w1s, w2s, and bs.\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Learning Curves, Overfitting, and Machine Learning (55 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know how to optimize, let's get some real machine learning done!\t\n",
    "\n",
    "Instead of the small dataset we had in questions 2, now let's use the the CBIS-DDSM (Curated Breast Imaging Subset of DDSM) dataset from <a href=\"https://wiki.cancerimagingarchive.net/display/Public/CBIS-DDSM#385f2cd4e86f4142b1d32bdb5803bd96\"> here</a>\n",
    "\n",
    "\n",
    "In this homework, we will *only* focus on the following items in the dataset:\t\n",
    "Mass-Training-Description (csv)\t\n",
    "Mass-Test-Description (csv)\t\n",
    "(Don't download the images on your laptop! That file is too big and we deal with it on the cluster later!)\n",
    "\n",
    "This dataset contains several features related to Mammography and detection of breast cancer. \n",
    "\n",
    "The Mass-Training-Description and Mass-Test-Description include these columns:\n",
    "\n",
    "patient_id\t\n",
    "breast_density\t\n",
    "left or right breast\t\n",
    "image view\t\t\n",
    "abnormality id\t\t\n",
    "abnormality type\t\n",
    "mass shape\t\n",
    "mass margins\t\n",
    "assessment\t\n",
    "pathology\n",
    "\n",
    "There is more data in this dataset, including images, but for this homework we will not focus on them.\n",
    "\n",
    "We are interested in 3.1-3.6 Using variables:\t\n",
    "\n",
    "breast_density\t\t\n",
    "image view\t\t\n",
    "abnormality id\t\t\t\n",
    "mass shape\t\n",
    "mass margins\n",
    "\n",
    "\n",
    "How well can we predict the **pathology type**?\n",
    "\n",
    "We can answer that by training a model on the Mass-Training-Description, and evaluating it on Mass-Test-Description. \n",
    "See questions 3.1 and 3.2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. (5 points)\n",
    "Write a script to prepare input [breast_density, image view, abnormality id, mass shape, mass margins] and output [pathology type].\n",
    "\n",
    "The output of your script should be a matrix X and a vector Y, where each row of X are input variables of a patient, and each row of Y is the pathology type class, for that patient. Create dummy variables for [image view, abnormality id, mass shape, and mass margins]. \n",
    "\n",
    "How many columns do you have now?\n",
    "\n",
    "Use *matplotlib.imshow* to visualize the X.\t\n",
    "(And if there are multiple equivalent rows per patient, keep only one of them - any, up to you)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. (2 points)\n",
    "Repeat Question 3.1 for the test set - remember to make sure you have same number of columns for test and train set!\n",
    "Use matplotlib.imshow(xtest, aspect='auto') to show the x dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3. Multi-layered-perceptron (15 points)\n",
    "\n",
    "Design a multi layer perceptron (MLP) with a single hidden layer which first maps the input to a vector of 100 hidden nodes, then feeds this vector to a fully connected layer to get the probability of 3 classes: BENIGN_WITHOUT_CALLBACK, BENIGN, MALIGNANT\n",
    "\n",
    "You can choose optimizer and loss function of your interest.\n",
    "\n",
    "Plot the ***average loss on all the train samples*** per epoch. (Stop the training after 1000 epochs). \n",
    "Also plot the **training** Area Under ROC curve (AUC) score of class \"MALIGNANT\" vs. Non-MALIGNANT class per epoch. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. (10 points)\n",
    "Now let's evaluate the same loss function over your ***test set***. \n",
    "Plot the ***average loss on all the test samples*** and the ***average loss on all the train samples*** per epoch in the same plot. (Stop the training after 1000 epochs)\n",
    "\n",
    "Also plot the **test set** Area Under ROC curve (AUC) score (per epoch) for class \"MALIGNANT\" vs. Non-MALIGNANT class. Plot both test set AUC and training set AUC (per epoch) in the same figure/plot. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5. (2 points)\n",
    "How many parameters you need to fit for your design?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6. (3 points)\n",
    "Design a multi-class **logistic regression** model which takes the input and outputs the probability of 3 classes. How many parameters you need to fit for your design?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7. (13 points)\n",
    "Now, let's add 2 more variables to the input: [left or right breast, abnormality type], and create their corresponding dummy variables. \n",
    "\n",
    "Build a new MLP model using similar architecture as before, with same number of hidden nodes. Train and evaluate that model for 1000 epochs, and plot the average traing set and average test set loss functions and AUCs given the new expanded feature sets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8. (5 points)\n",
    "Which model works better? Do you think adding 2 additional features help? Why? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Question: Fairness, Accountability and Transparency in AI (10 points)\n",
    "------------------------------------------\n",
    "In this question, we will review the following publication:\n",
    "\n",
    "Mitchell, M., Wu, S., Zaldivar, A., Barnes, P., Vasserman, L., Hutchinson, B., Spitzer, E., Raji, I.D. and Gebru, T., 2019, January. **Model cards for model reporting**. In Proceedings of the conference on fairness, accountability, and transparency (pp. 220-229). Link: https://arxiv.org/abs/1810.03993\n",
    "\n",
    "Read this paper. Please share with us in a few bullet points for each:\n",
    "\n",
    "- What are the reasons authors suggest model cards?\n",
    "- What are the items that can be included in the model card?\n",
    "- Your thoughts about how this paper can be relevant to healthcare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
